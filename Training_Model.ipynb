{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moderate-regular",
   "metadata": {},
   "source": [
    "## Prueba Técnica Datta\n",
    "### Computer Vision ----> Clasificación de Números realizados con la Mano\n",
    "\n",
    " Código utilizado para el entrenamiento de una red neuronal convolucional __CNN__ con __TensorFlow__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lonely-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np \n",
    "import random\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "piano-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de datos\n",
    "dataset_url = \"https://trascenderglobaldocs.s3.amazonaws.com/admisiones/64x64_SIGNS.zip\"\n",
    "data_zip = tf.keras.utils.get_file(origin=dataset_url, \n",
    "                                          fname='64x64_SIGNS.zip', \n",
    "                                          extract=True)\n",
    "# Directorio donde se almacenan los datos\n",
    "data_dir = os.path.dirname(data_zip) + '/64x64_SIGNS' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "contained-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de las Imágenes\n",
    "img_size = 64\n",
    "# Lista para Datos de Entrenamiento\n",
    "training_data = []\n",
    "# Lista para Datos de Validación\n",
    "val_data = []\n",
    "\n",
    "# Función para convertir Imagen a Arreglo\n",
    "def img_to_array():\n",
    "    # Listas para Datos de Entrenamiento\n",
    "    X = []\n",
    "    y = []\n",
    "    # Listas para Datos de Validación\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    \n",
    "    # Directorio Datos de Entrenamiento\n",
    "    path = os.path.join(data_dir, 'train_signs')\n",
    "    \n",
    "    for img in os.listdir(path):\n",
    "            new_path = os.path.join(path, img)\n",
    "            \n",
    "            try:\n",
    "                img_array = cv2.imread(new_path) # Leer imagen\n",
    "                label = int(img[0]) # Etiqueta de la imagen\n",
    "                training_data.append([img_array, label]) # Adición como Dato de Entrenamiento\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "    random.shuffle(training_data) # Mezcla de Datos de Entrenamiento\n",
    "    \n",
    "    # Separación de datos con etiqueta\n",
    "    for samples, labels in training_data:\n",
    "        X.append(samples)\n",
    "        y.append(labels)\n",
    "        \n",
    "    # Convertir lista a np.array    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Guardar Datos para Entrenamiento\n",
    "    np.save('samples', X)\n",
    "    np.save('labels', y)\n",
    "    \n",
    "    # Se repite el proceso para los datos de Validación\n",
    "    path = os.path.join(data_dir, 'val_signs')\n",
    "    \n",
    "    for img in os.listdir(path):\n",
    "            new_path = os.path.join(path, img)\n",
    "            \n",
    "            try:\n",
    "                img_array = cv2.imread(new_path)\n",
    "                label = int(img[0])\n",
    "                val_data.append([img_array, label])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "    random.shuffle(val_data)\n",
    "    \n",
    "    for samples, labels in val_data:\n",
    "        X_val.append(samples)\n",
    "        y_val.append(labels)\n",
    "        \n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    print(y.shape)\n",
    "    print(y_val.shape)\n",
    "    np.save('samples_val', X_val)\n",
    "    np.save('labels_val', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mounted-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para definir vector de Salida de Categorías\n",
    "def to_categorical(array):\n",
    "    one_hot = np.zeros((len(array), 6)) # 6 es el número de categorías\n",
    "    \n",
    "    for idx, num in enumerate(array):\n",
    "        one_hot[idx][num] = 1 # Se asigna 1 a la posición del array que corresponde a su etiqueta (label)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "scheduled-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), input_shape=(64,64,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "metric-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para Entrenamiento del modelo\n",
    "def train():\n",
    "    # Cargar Datos de Entrenamiento\n",
    "    samples = np.load('samples.npy')\n",
    "    labels = to_categorical(np.load('labels.npy'))\n",
    "    \n",
    "    # Cargar Datos de Validación\n",
    "    samples_val = np.load('samples_val.npy')\n",
    "    labels_val = to_categorical(np.load('labels_val.npy'))\n",
    "    \n",
    "    # Normalización de los Datos (0-1)\n",
    "    samples = samples.astype('float32') / 255\n",
    "    samples_val = samples_val.astype('float32') / 255\n",
    "    \n",
    "    # Entrenamiento\n",
    "    network = build_model()\n",
    "    \n",
    "    network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    \n",
    "    network.fit(samples, labels, batch_size=64, epochs=20, validation_data=(samples_val, labels_val))\n",
    "\n",
    "    network.save('Network.model')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "devoted-belfast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - 29s 1s/step - loss: 1.8448 - accuracy: 0.2059 - val_loss: 1.6631 - val_accuracy: 0.4167\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 22s 830ms/step - loss: 1.5040 - accuracy: 0.4238 - val_loss: 1.4534 - val_accuracy: 0.3935\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 22s 833ms/step - loss: 1.1480 - accuracy: 0.5749 - val_loss: 1.0812 - val_accuracy: 0.5648\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.9139 - accuracy: 0.6604 - val_loss: 0.7835 - val_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 23s 842ms/step - loss: 0.6701 - accuracy: 0.7679 - val_loss: 0.6412 - val_accuracy: 0.7731\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 22s 832ms/step - loss: 0.4733 - accuracy: 0.8439 - val_loss: 0.6418 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4018 - accuracy: 0.8867 - val_loss: 0.6316 - val_accuracy: 0.7917\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 22s 831ms/step - loss: 0.2786 - accuracy: 0.9135 - val_loss: 0.4776 - val_accuracy: 0.8287\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.2007 - accuracy: 0.9350 - val_loss: 0.9815 - val_accuracy: 0.6759\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 22s 835ms/step - loss: 0.2473 - accuracy: 0.9273 - val_loss: 0.4771 - val_accuracy: 0.8426\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 25s 939ms/step - loss: 0.1487 - accuracy: 0.9460 - val_loss: 0.3995 - val_accuracy: 0.8657\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.0974 - accuracy: 0.9738 - val_loss: 0.5836 - val_accuracy: 0.8102\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 23s 852ms/step - loss: 0.0803 - accuracy: 0.9680 - val_loss: 0.3467 - val_accuracy: 0.8981\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.0520 - accuracy: 0.9865 - val_loss: 0.3501 - val_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 22s 831ms/step - loss: 0.0364 - accuracy: 0.9924 - val_loss: 0.3668 - val_accuracy: 0.8935\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.0184 - accuracy: 0.9984 - val_loss: 0.3459 - val_accuracy: 0.9028\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 27s 971ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.3265 - val_accuracy: 0.9120\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.8935\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 23s 835ms/step - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.3779 - val_accuracy: 0.8981\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 23s 835ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8935\n",
      "INFO:tensorflow:Assets written to: Network.model/assets\n"
     ]
    }
   ],
   "source": [
    "# Si ya se tienen los Datos de Entrenamiento, se procede al Entrenamiento\n",
    "if (os.path.isfile('samples.npy') and os.path.isfile('labels.npy')):\n",
    "    train()\n",
    "    #Sino, se obtienen los datos y luego se entrena\n",
    "else:\n",
    "    img_to_array()\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
